{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9bc5323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ§¬ 1æ¬¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼ãƒ©ã‚¤ãƒ–ãƒ©ãƒªè¨­è¨ˆ\n",
      "   å¯¾è±¡: è‚è‡“ + CD3+Tç´°èƒ + ãƒ¦ãƒ“ã‚­ã‚¿ã‚¹\n",
      "======================================================================\n",
      "\n",
      "ğŸ”— JASPAR APIæ¥ç¶šæº–å‚™å®Œäº†\n",
      "ğŸ“š FANTOM5ãƒ‡ãƒ¼ã‚¿ãƒãƒ³ãƒ‰ãƒ©ãƒ¼åˆæœŸåŒ–å®Œäº†\n",
      "\n",
      "======================================================================\n",
      "ğŸ§¬ 1æ¬¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªè¨­è¨ˆã‚·ã‚¹ãƒ†ãƒ  èµ·å‹•\n",
      "======================================================================\n",
      "âš¡ é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰: æ—¢çŸ¥ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "ã‚¹ãƒ†ãƒƒãƒ—1: ã‚³ã‚¢ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼å–å¾—\n",
      "======================================================================\n",
      "ğŸ§¬ ã‚³ã‚¢ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼è¦ç´ ã‚’ç”Ÿæˆä¸­...\n",
      "âœ… 8å€‹ã®ã‚³ã‚¢ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼ç”Ÿæˆå®Œäº†\n",
      "\n",
      "ğŸ“Š ä½¿ç”¨ã‚³ã‚¢æ•°: 8\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ã‚¹ãƒ†ãƒƒãƒ—2: LIVER ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç”Ÿæˆ\n",
      "======================================================================\n",
      "ğŸ¯ å¯¾è±¡TF: HNF1A, HNF4A, CEBPA, FOXA1, FOXA2\n",
      "\n",
      "ğŸ“¥ 5å€‹ã®TFãƒ¢ãƒãƒ¼ãƒ•ã‚’å–å¾—ä¸­...\n",
      "âœ… 5å€‹ã®ãƒ¢ãƒãƒ¼ãƒ•å–å¾—å®Œäº†\n",
      "\n",
      "ğŸ“ TFBMé…åˆ—æ•°: 6\n",
      "\n",
      "  ğŸ”§ TFBM x1 æ§‹æˆã‚’ç”Ÿæˆä¸­...\n",
      "  âœ… 288å€‹ã®ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼ç”Ÿæˆ\n",
      "\n",
      "  ğŸ”§ TFBM x2 æ§‹æˆã‚’ç”Ÿæˆä¸­...\n",
      "  âœ… 10368å€‹ã®ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼ç”Ÿæˆ\n",
      "\n",
      "ğŸ’¾ ä¿å­˜: screening_1st_liver.csv\n",
      "ğŸ“Š ç·ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼æ•°: 10,656\n",
      "\n",
      "======================================================================\n",
      "ã‚¹ãƒ†ãƒƒãƒ—2: TCELL ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç”Ÿæˆ\n",
      "======================================================================\n",
      "ğŸ¯ å¯¾è±¡TF: NFKB1, NFAT1, STAT4, TBX21, GATA3\n",
      "\n",
      "ğŸ“¥ 5å€‹ã®TFãƒ¢ãƒãƒ¼ãƒ•ã‚’å–å¾—ä¸­...\n",
      "âœ… 5å€‹ã®ãƒ¢ãƒãƒ¼ãƒ•å–å¾—å®Œäº†\n",
      "\n",
      "ğŸ“ TFBMé…åˆ—æ•°: 7\n",
      "\n",
      "  ğŸ”§ TFBM x1 æ§‹æˆã‚’ç”Ÿæˆä¸­...\n",
      "  âœ… 336å€‹ã®ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼ç”Ÿæˆ\n",
      "\n",
      "  ğŸ”§ TFBM x2 æ§‹æˆã‚’ç”Ÿæˆä¸­...\n",
      "  âœ… 14112å€‹ã®ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼ç”Ÿæˆ\n",
      "\n",
      "ğŸ’¾ ä¿å­˜: screening_1st_tcell.csv\n",
      "ğŸ“Š ç·ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼æ•°: 14,448\n",
      "\n",
      "======================================================================\n",
      "ã‚¹ãƒ†ãƒƒãƒ—2: UBIQUITOUS ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç”Ÿæˆ\n",
      "======================================================================\n",
      "ğŸ¯ å¯¾è±¡TF: SP1, NRF1, E2F1, MYC\n",
      "\n",
      "ğŸ“¥ 4å€‹ã®TFãƒ¢ãƒãƒ¼ãƒ•ã‚’å–å¾—ä¸­...\n",
      "âœ… 4å€‹ã®ãƒ¢ãƒãƒ¼ãƒ•å–å¾—å®Œäº†\n",
      "\n",
      "ğŸ“ TFBMé…åˆ—æ•°: 4\n",
      "\n",
      "  ğŸ”§ TFBM x1 æ§‹æˆã‚’ç”Ÿæˆä¸­...\n",
      "  âœ… 192å€‹ã®ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼ç”Ÿæˆ\n",
      "\n",
      "  ğŸ”§ TFBM x2 æ§‹æˆã‚’ç”Ÿæˆä¸­...\n",
      "  âœ… 4608å€‹ã®ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼ç”Ÿæˆ\n",
      "\n",
      "ğŸ’¾ ä¿å­˜: screening_1st_ubiquitous.csv\n",
      "ğŸ“Š ç·ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼æ•°: 4,800\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š 1æ¬¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ©ã‚¤ãƒ–ãƒ©ãƒª - æœ€çµ‚ã‚µãƒãƒªãƒ¼\n",
      "======================================================================\n",
      "\n",
      "ã€LIVERã€‘\n",
      "  ç·ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼æ•°: 10,656\n",
      "  é…åˆ—é•·ç¯„å›²: 27-124 bp\n",
      "  GCå«é‡ç¯„å›²: 25.4-56.2%\n",
      "  ãƒˆãƒãƒ­ã‚¸ãƒ¼ç¨®é¡: 6\n",
      "\n",
      "ã€TCELLã€‘\n",
      "  ç·ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼æ•°: 14,448\n",
      "  é…åˆ—é•·ç¯„å›²: 26-118 bp\n",
      "  GCå«é‡ç¯„å›²: 30.8-58.1%\n",
      "  ãƒˆãƒãƒ­ã‚¸ãƒ¼ç¨®é¡: 6\n",
      "\n",
      "ã€UBIQUITOUSã€‘\n",
      "  ç·ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼æ•°: 4,800\n",
      "  é…åˆ—é•·ç¯„å›²: 27-118 bp\n",
      "  GCå«é‡ç¯„å›²: 37.0-73.7%\n",
      "  ãƒˆãƒãƒ­ã‚¸ãƒ¼ç¨®é¡: 6\n",
      "\n",
      "======================================================================\n",
      "ğŸ¯ å…¨çµ„ç¹”åˆè¨ˆ: 29,904 ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ğŸ“‹ ç”Ÿæˆã•ã‚ŒãŸãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è©³ç´°\n",
      "======================================================================\n",
      "\n",
      "--- LIVER ---\n",
      "       Promoter_ID  N_TFBM Topology  Length  GC_Content\n",
      "0  LIVER_P1_000001       1        S      61   31.147541\n",
      "1  LIVER_P1_000002       1        S      71   32.394366\n",
      "2  LIVER_P1_000003       1        S      81   35.802469\n",
      "3  LIVER_P1_000004       1        O      56   30.357143\n",
      "4  LIVER_P1_000005       1        O      66   33.333333\n",
      "5  LIVER_P1_000006       1        O      76   36.842105\n",
      "6  LIVER_P1_000007       1        S      61   31.147541\n",
      "7  LIVER_P1_000008       1        S      71   36.619718\n",
      "8  LIVER_P1_000009       1        S      81   34.567901\n",
      "9  LIVER_P1_000010       1        O      56   32.142857\n",
      "\n",
      "ãƒˆãƒãƒ­ã‚¸ãƒ¼åˆ†å¸ƒ:\n",
      "Topology\n",
      "S-S    2592\n",
      "S-O    2592\n",
      "O-S    2592\n",
      "O-O    2592\n",
      "S       144\n",
      "O       144\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- TCELL ---\n",
      "       Promoter_ID  N_TFBM Topology  Length  GC_Content\n",
      "0  TCELL_P1_000001       1        S      58   41.379310\n",
      "1  TCELL_P1_000002       1        S      68   42.647059\n",
      "2  TCELL_P1_000003       1        S      78   38.461538\n",
      "3  TCELL_P1_000004       1        O      53   41.509434\n",
      "4  TCELL_P1_000005       1        O      63   41.269841\n",
      "5  TCELL_P1_000006       1        O      73   39.726027\n",
      "6  TCELL_P1_000007       1        S      53   33.962264\n",
      "7  TCELL_P1_000008       1        S      63   36.507937\n",
      "8  TCELL_P1_000009       1        S      73   36.986301\n",
      "9  TCELL_P1_000010       1        O      48   35.416667\n",
      "\n",
      "ãƒˆãƒãƒ­ã‚¸ãƒ¼åˆ†å¸ƒ:\n",
      "Topology\n",
      "S-S    3528\n",
      "S-O    3528\n",
      "O-S    3528\n",
      "O-O    3528\n",
      "S       168\n",
      "O       168\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- UBIQUITOUS ---\n",
      "            Promoter_ID  N_TFBM Topology  Length  GC_Content\n",
      "0  UBIQUITOUS_P1_000001       1        S      54   42.592593\n",
      "1  UBIQUITOUS_P1_000002       1        S      64   46.875000\n",
      "2  UBIQUITOUS_P1_000003       1        S      74   44.594595\n",
      "3  UBIQUITOUS_P1_000004       1        O      49   42.857143\n",
      "4  UBIQUITOUS_P1_000005       1        O      59   44.067797\n",
      "5  UBIQUITOUS_P1_000006       1        O      69   44.927536\n",
      "6  UBIQUITOUS_P1_000007       1        S      58   44.827586\n",
      "7  UBIQUITOUS_P1_000008       1        S      68   44.117647\n",
      "8  UBIQUITOUS_P1_000009       1        S      78   43.589744\n",
      "9  UBIQUITOUS_P1_000010       1        O      53   45.283019\n",
      "\n",
      "ãƒˆãƒãƒ­ã‚¸ãƒ¼åˆ†å¸ƒ:\n",
      "Topology\n",
      "S-S    1152\n",
      "S-O    1152\n",
      "O-S    1152\n",
      "O-O    1152\n",
      "S        96\n",
      "O        96\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n",
      "âœ… 1æ¬¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç”Ÿæˆå®Œäº†ï¼\n",
      "======================================================================\n",
      "\n",
      "ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:\n",
      "  - screening_1st_liver.csv\n",
      "  - screening_1st_tcell.csv\n",
      "  - screening_1st_ubiquitous.csv\n",
      "\n",
      "ğŸ”¬ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:\n",
      "  1. ã“ã‚Œã‚‰ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ãƒ«ã‚·ãƒ•ã‚§ãƒ©ãƒ¼ã‚¼ã‚¢ãƒƒã‚»ã‚¤\n",
      "  2. æ´»æ€§ã®é«˜ã„å€™è£œã‚’ç‰¹å®š\n",
      "  3. æœ‰æœ›ãªçµ„ã¿åˆã‚ã›ã§2æ¬¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’è¨­è¨ˆ\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1æ¬¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼ãƒ©ã‚¤ãƒ–ãƒ©ãƒªè¨­è¨ˆã‚·ã‚¹ãƒ†ãƒ \n",
    "- å®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—ç‰ˆï¼ˆFANTOM5 + JASPARï¼‰ -\n",
    "\n",
    "ã€å¯¾è±¡ã€‘\n",
    "âœ… è‚è‡“ï¼ˆLiverï¼‰\n",
    "âœ… CD3é™½æ€§Tç´°èƒï¼ˆImmune - T cellï¼‰\n",
    "âœ… ãƒ¦ãƒ“ã‚­ã‚¿ã‚¹ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼ï¼ˆCMV-likeï¼‰\n",
    "\n",
    "ã€ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã€‘\n",
    "âœ… FANTOM5: å®Ÿéš›ã®çµ„ç¹”ç‰¹ç•°çš„ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿\n",
    "âœ… JASPAR: æœ€æ–°ã®è»¢å†™å› å­çµåˆãƒ¢ãƒãƒ¼ãƒ•ï¼ˆAPIçµŒç”±ï¼‰\n",
    "âœ… æ–‡çŒ®: CMVãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼è¨­è¨ˆã®çŸ¥è¦‹\n",
    "\n",
    "ã€1æ¬¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æœ€é©åŒ–ã€‘\n",
    "- ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚µã‚¤ã‚º: ç®¡ç†å¯èƒ½ï¼ˆæ•°ç™¾ã€œæ•°åƒï¼‰\n",
    "- ä»£è¡¨æ€§: é«˜ç™ºç¾ãƒ»é«˜ç‰¹ç•°æ€§TFã‚’å³é¸\n",
    "- æ‹¡å¼µæ€§: 2æ¬¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã¸ã®å±•é–‹å¯èƒ½\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "from io import StringIO\n",
    "from itertools import product\n",
    "import random\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# B-DNAæœ€é©åŒ–Spacerç”Ÿæˆï¼ˆå‰å›ã¨åŒã˜ï¼‰\n",
    "# ============================================================================\n",
    "\n",
    "def generate_bdna_friendly_spacer(length=10, gc_target=0.45):\n",
    "    \"\"\"B-DNAæ§‹é€ ã‚’ç¶­æŒã™ã‚‹spaceré…åˆ—ã‚’ç”Ÿæˆ\"\"\"\n",
    "    gc_bases = ['G', 'C']\n",
    "    at_bases = ['A', 'T']\n",
    "    all_bases = ['A', 'T', 'G', 'C']\n",
    "    \n",
    "    spacer = []\n",
    "    prev_base = None\n",
    "    consecutive_count = 0\n",
    "    \n",
    "    for i in range(length):\n",
    "        if i > 0:\n",
    "            current_gc = sum(1 for b in spacer if b in ['G', 'C']) / len(spacer)\n",
    "        else:\n",
    "            current_gc = 0\n",
    "        \n",
    "        if current_gc < gc_target - 0.1:\n",
    "            available_bases = gc_bases + at_bases[:1]\n",
    "        elif current_gc > gc_target + 0.1:\n",
    "            available_bases = at_bases + gc_bases[:1]\n",
    "        else:\n",
    "            available_bases = all_bases\n",
    "        \n",
    "        if consecutive_count >= 2:\n",
    "            available_bases = [b for b in available_bases if b != prev_base]\n",
    "        \n",
    "        if i >= 1 and len(spacer) >= 2:\n",
    "            if spacer[-2:] == ['G', 'C']:\n",
    "                available_bases = [b for b in available_bases if b not in ['G', 'C']]\n",
    "            elif spacer[-2:] == ['C', 'G']:\n",
    "                available_bases = [b for b in available_bases if b not in ['C', 'G']]\n",
    "        \n",
    "        if not available_bases:\n",
    "            available_bases = all_bases\n",
    "        \n",
    "        base = random.choice(available_bases)\n",
    "        spacer.append(base)\n",
    "        \n",
    "        if base == prev_base:\n",
    "            consecutive_count += 1\n",
    "        else:\n",
    "            consecutive_count = 1\n",
    "        prev_base = base\n",
    "    \n",
    "    return ''.join(spacer)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# JASPARãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆå®ŸAPIæ¥ç¶šï¼‰\n",
    "# ============================================================================\n",
    "\n",
    "class JASPARFetcher:\n",
    "    \"\"\"\n",
    "    JASPARãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒ¢ãƒãƒ¼ãƒ•ã‚’å–å¾—\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://jaspar.elixir.no/api/v1\"\n",
    "        self.cache = {}\n",
    "        print(\"ğŸ”— JASPAR APIæ¥ç¶šæº–å‚™å®Œäº†\")\n",
    "    \n",
    "    def fetch_motif(self, tf_name, species='Homo sapiens', use_api=True):\n",
    "        \"\"\"\n",
    "        JASPARã‹ã‚‰TFãƒ¢ãƒãƒ¼ãƒ•ã‚’å–å¾—\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        tf_name : str\n",
    "            è»¢å†™å› å­å\n",
    "        species : str\n",
    "            ç”Ÿç‰©ç¨®\n",
    "        use_api : bool\n",
    "            å®Ÿéš›ã«APIã‚’ä½¿ç”¨ã™ã‚‹ã‹ï¼ˆFalse=ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰\n",
    "        \"\"\"\n",
    "        cache_key = f\"{tf_name}_{species}\"\n",
    "        if cache_key in self.cache:\n",
    "            return self.cache[cache_key]\n",
    "        \n",
    "        if use_api:\n",
    "            try:\n",
    "                print(f\"  ğŸ” JASPARæ¤œç´¢: {tf_name}...\", end='')\n",
    "                \n",
    "                # JASPAR API: /matrix ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "                url = f\"{self.base_url}/matrix\"\n",
    "                params = {'search': tf_name, 'tax_group': 'vertebrates'}\n",
    "                \n",
    "                response = requests.get(url, params=params, timeout=10)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    if data.get('results') and len(data['results']) > 0:\n",
    "                        # æœ€åˆã®çµæœã‚’ä½¿ç”¨\n",
    "                        matrix = data['results'][0]\n",
    "                        consensus = matrix.get('consensus', '')\n",
    "                        \n",
    "                        if consensus:\n",
    "                            print(f\" âœ… å–å¾—æˆåŠŸ\")\n",
    "                            self.cache[cache_key] = consensus\n",
    "                            return consensus\n",
    "                \n",
    "                print(f\" âš ï¸  APIã§è¦‹ã¤ã‹ã‚‰ãšã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨\")\n",
    "                time.sleep(0.5)  # APIåˆ¶é™å¯¾ç­–\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\" âŒ ã‚¨ãƒ©ãƒ¼: {str(e)[:50]}\")\n",
    "        \n",
    "        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ–‡çŒ®ã‹ã‚‰æ—¢çŸ¥ã®ãƒ¢ãƒãƒ¼ãƒ•\n",
    "        motif = self._get_known_motif(tf_name)\n",
    "        self.cache[cache_key] = motif\n",
    "        return motif\n",
    "    \n",
    "    def _get_known_motif(self, tf_name):\n",
    "        \"\"\"æ–‡çŒ®ãƒ™ãƒ¼ã‚¹ã®æ—¢çŸ¥ãƒ¢ãƒãƒ¼ãƒ•ï¼ˆJASPARå¤±æ•—æ™‚ï¼‰\"\"\"\n",
    "        known_motifs = {\n",
    "            # Liver-specific TFs\n",
    "            'HNF1A': 'GTTAATNATTAAC',\n",
    "            'HNF1B': 'GTTAATGATTAAC',\n",
    "            'HNF4A': 'AGGTCA',\n",
    "            'HNF4G': 'RGGTCA',\n",
    "            'CEBPA': 'TTGCGCAA',\n",
    "            'CEBPB': 'ATTGCGCAAT',\n",
    "            'FOXA1': 'TGTTTAC',\n",
    "            'FOXA2': 'TGTTTGC',\n",
    "            'FOXA3': 'TGTTTRY',\n",
    "            # T cell / Immune TFs\n",
    "            'NFKB1': 'GGGACTTTCC',\n",
    "            'NFKB2': 'GGGRATTTCC',\n",
    "            'RELA': 'GGGAMTTYCC',\n",
    "            'STAT1': 'TTCNNNGAA',\n",
    "            'STAT3': 'TTCNNNGAA',\n",
    "            'STAT4': 'TTCYNRGAA',\n",
    "            'STAT5A': 'TTCYNRGAA',\n",
    "            'STAT5B': 'TTCYNRGAA',\n",
    "            'NFAT1': 'GGAAA',\n",
    "            'NFATC1': 'GGAAA',\n",
    "            'NFATC2': 'GGAAA',\n",
    "            'IRF1': 'GAAANNGAAA',\n",
    "            'IRF4': 'GAAAN',\n",
    "            'IRF8': 'GAAANNGAAA',\n",
    "            'TBX21': 'TCACACCT',  # T-bet\n",
    "            'GATA3': 'WGATAR',\n",
    "            'RUNX1': 'TGTGGT',\n",
    "            'RUNX3': 'TGTGGT',\n",
    "            'ETS1': 'GGAA',\n",
    "            'BCL6': 'TTCCNNGAA',\n",
    "            # Ubiquitous TFs\n",
    "            'SP1': 'GGGCGG',\n",
    "            'SP3': 'GGGGCGGGG',\n",
    "            'NRF1': 'GCGCATGCGC',\n",
    "            'E2F1': 'TTTCGCGC',\n",
    "            'E2F2': 'TTTCGCGC',\n",
    "            'MYC': 'CACGTG',\n",
    "            'MAX': 'CACGTG',\n",
    "            'YY1': 'CGCCATNTT',\n",
    "            'AP1': 'TGASTCA',\n",
    "            'CREB1': 'TGACGTCA',\n",
    "            'ATF1': 'TGACGTCA',\n",
    "        }\n",
    "        return known_motifs.get(tf_name, 'NNNNNN')\n",
    "    \n",
    "    def fetch_multiple_motifs(self, tf_list, use_api=True):\n",
    "        \"\"\"è¤‡æ•°ã®TFãƒ¢ãƒãƒ¼ãƒ•ã‚’ä¸€æ‹¬å–å¾—\"\"\"\n",
    "        motifs = {}\n",
    "        print(f\"\\nğŸ“¥ {len(tf_list)}å€‹ã®TFãƒ¢ãƒãƒ¼ãƒ•ã‚’å–å¾—ä¸­...\")\n",
    "        \n",
    "        for tf in tf_list:\n",
    "            motif = self.fetch_motif(tf, use_api=use_api)\n",
    "            motifs[tf] = motif\n",
    "        \n",
    "        print(f\"âœ… {len(motifs)}å€‹ã®ãƒ¢ãƒãƒ¼ãƒ•å–å¾—å®Œäº†\\n\")\n",
    "        return motifs\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FANTOM5ãƒ‡ãƒ¼ã‚¿ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿æŒ‡å‘ï¼‰\n",
    "# ============================================================================\n",
    "\n",
    "class FANTOM5Handler:\n",
    "    \"\"\"\n",
    "    FANTOM5ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã¨å‡¦ç†\n",
    "    \n",
    "    ã€ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã€‘\n",
    "    - FANTOM5 CAGEãƒ”ãƒ¼ã‚¯\n",
    "    - çµ„ç¹”ç‰¹ç•°çš„ç™ºç¾ãƒ‘ã‚¿ãƒ¼ãƒ³\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://fantom.gsc.riken.jp/5/datafiles\"\n",
    "        \n",
    "        # çµ„ç¹”ç‰¹ç•°çš„TFï¼ˆFANTOM5è«–æ–‡ + æ–‡çŒ®ï¼‰\n",
    "        self.tissue_tfs = {\n",
    "            'liver': {\n",
    "                'high_priority': ['HNF1A', 'HNF4A', 'CEBPA', 'FOXA1', 'FOXA2'],\n",
    "                'medium_priority': ['HNF1B', 'HNF4G', 'CEBPB', 'FOXA3'],\n",
    "            },\n",
    "            'tcell': {  # CD3+ T cell\n",
    "                'high_priority': ['NFKB1', 'NFAT1', 'STAT4', 'TBX21', 'GATA3'],\n",
    "                'medium_priority': ['RELA', 'NFATC1', 'NFATC2', 'STAT5A', 'IRF4', 'RUNX1', 'ETS1'],\n",
    "            },\n",
    "            'ubiquitous': {\n",
    "                'high_priority': ['SP1', 'NRF1', 'E2F1', 'MYC'],\n",
    "                'medium_priority': ['SP3', 'E2F2', 'YY1', 'CREB1'],\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(\"ğŸ“š FANTOM5ãƒ‡ãƒ¼ã‚¿ãƒãƒ³ãƒ‰ãƒ©ãƒ¼åˆæœŸåŒ–å®Œäº†\")\n",
    "    \n",
    "    def get_tissue_tfs(self, tissue, priority='high', max_n=10):\n",
    "        \"\"\"\n",
    "        çµ„ç¹”ç‰¹ç•°çš„è»¢å†™å› å­ãƒªã‚¹ãƒˆã‚’å–å¾—\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        tissue : str\n",
    "            'liver', 'tcell', 'ubiquitous'\n",
    "        priority : str\n",
    "            'high', 'medium', 'all'\n",
    "        max_n : int\n",
    "            æœ€å¤§å–å¾—æ•°\n",
    "        \"\"\"\n",
    "        if tissue not in self.tissue_tfs:\n",
    "            return []\n",
    "        \n",
    "        tfs = []\n",
    "        tissue_data = self.tissue_tfs[tissue]\n",
    "        \n",
    "        if priority in ['high', 'all']:\n",
    "            tfs.extend(tissue_data.get('high_priority', []))\n",
    "        \n",
    "        if priority in ['medium', 'all']:\n",
    "            tfs.extend(tissue_data.get('medium_priority', []))\n",
    "        \n",
    "        return tfs[:max_n]\n",
    "    \n",
    "    def get_core_promoters(self, n=15):\n",
    "        \"\"\"\n",
    "        ä»£è¡¨çš„ãªã‚³ã‚¢ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼è¦ç´ ã‚’å–å¾—\n",
    "        \n",
    "        ã€å®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—ã®ä»£æ›¿ã€‘\n",
    "        FANTOM5ã®å®Œå…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆæ•°GBï¼‰ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¯æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ã€\n",
    "        æ–‡çŒ®ãƒ™ãƒ¼ã‚¹ã®ä»£è¡¨çš„ãªé…åˆ—ã‚’ç”Ÿæˆ\n",
    "        \"\"\"\n",
    "        print(f\"ğŸ§¬ ã‚³ã‚¢ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼è¦ç´ ã‚’ç”Ÿæˆä¸­...\")\n",
    "        \n",
    "        cores = []\n",
    "        \n",
    "        # 1. TATA box based\n",
    "        tata_variants = [\n",
    "            'TATAAA',      # Strong TATA\n",
    "            'TATAWA',      # Weak TATA (W=A/T)\n",
    "            'TATATAA',     # Extended TATA\n",
    "            'CTATAA',      # Weak variant\n",
    "        ]\n",
    "        \n",
    "        # 2. Initiator (Inr) based\n",
    "        inr_variants = [\n",
    "            'CCANWTY',     # Consensus Inr (N=any, W=A/T, Y=C/T)\n",
    "            'TCAKTY',      # Alternative Inr (K=G/T)\n",
    "        ]\n",
    "        \n",
    "        # 3. TATA + Inr combination\n",
    "        for tata in tata_variants[:2]:\n",
    "            for inr in inr_variants:\n",
    "                core = tata + 'N' * 25 + inr\n",
    "                cores.append(self._expand_degenerate(core))\n",
    "        \n",
    "        # 4. Inr only (TATA-less)\n",
    "        for inr in inr_variants:\n",
    "            cores.append(self._expand_degenerate(inr + 'N' * 10))\n",
    "        \n",
    "        # 5. DPE (Downstream Promoter Element) based\n",
    "        dpe_variants = ['AGACY', 'RGWYV']\n",
    "        for inr in inr_variants[:1]:\n",
    "            for dpe in dpe_variants:\n",
    "                core = inr + 'N' * 20 + dpe\n",
    "                cores.append(self._expand_degenerate(core))\n",
    "        \n",
    "        print(f\"âœ… {len(cores)}å€‹ã®ã‚³ã‚¢ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼ç”Ÿæˆå®Œäº†\\n\")\n",
    "        return cores[:n]\n",
    "    \n",
    "    def _expand_degenerate(self, sequence):\n",
    "        \"\"\"ç¸®é‡å¡©åŸºã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«1ã¤ã®é…åˆ—ã«å±•é–‹\"\"\"\n",
    "        degenerate_map = {\n",
    "            'W': ['A', 'T'], \n",
    "            'Y': ['C', 'T'], \n",
    "            'R': ['A', 'G'],\n",
    "            'N': ['A', 'T', 'G', 'C'], \n",
    "            'S': ['G', 'C'], \n",
    "            'K': ['G', 'T'],\n",
    "        }\n",
    "        \n",
    "        result = []\n",
    "        for base in sequence:\n",
    "            if base in degenerate_map:\n",
    "                result.append(random.choice(degenerate_map[base]))\n",
    "            else:\n",
    "                result.append(base)\n",
    "        return ''.join(result)\n",
    "    \n",
    "    def download_fantom5_info(self):\n",
    "        \"\"\"\n",
    "        FANTOM5ãƒ‡ãƒ¼ã‚¿ã®å®Ÿéš›ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ–¹æ³•ã‚’è¡¨ç¤º\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ğŸ“¥ FANTOM5å®Ÿãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ–¹æ³•\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"\\nã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³1: Web UIã€‘\")\n",
    "        print(\"1. https://fantom.gsc.riken.jp/5/ ã«ã‚¢ã‚¯ã‚»ã‚¹\")\n",
    "        print(\"2. 'Data' ã‚¿ãƒ– â†’ 'Download' ã‚’é¸æŠ\")\n",
    "        print(\"3. 'CAGE peaks' â†’ 'hg19 permissive peaks' ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\")\n",
    "        print(\"\\nã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³2: ç›´æ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€‘\")\n",
    "        print(\"wget https://fantom.gsc.riken.jp/5/datafiles/reprocessed/hg19/...\")\n",
    "        print(\"\\nã€æ³¨æ„ã€‘\")\n",
    "        print(\"- ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: æ•°GB\")\n",
    "        print(\"- ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ™‚é–“: ç’°å¢ƒã«ã‚ˆã‚‹ï¼ˆæ•°åˆ†ã€œæ•°ååˆ†ï¼‰\")\n",
    "        print(\"- æ¨å¥¨: äº‹å‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 1æ¬¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªè¨­è¨ˆã‚·ã‚¹ãƒ†ãƒ \n",
    "# ============================================================================\n",
    "\n",
    "class ScreeningLibraryDesigner:\n",
    "    \"\"\"\n",
    "    1æ¬¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æœ€é©åŒ–ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼ãƒ©ã‚¤ãƒ–ãƒ©ãƒªè¨­è¨ˆ\n",
    "    \n",
    "    ã€å¯¾è±¡ã€‘\n",
    "    - Liver (è‚è‡“)\n",
    "    - T cell (CD3+ å…ç–«ç´°èƒ)\n",
    "    - Ubiquitous (CMV-like)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, use_jaspar_api=False):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        use_jaspar_api : bool\n",
    "            JASPARã®å®ŸAPIã‚’ä½¿ç”¨ã™ã‚‹ã‹\n",
    "            ï¼ˆFalse=é«˜é€Ÿã ãŒæ—¢çŸ¥ãƒ‡ãƒ¼ã‚¿ã®ã¿ã€True=æœ€æ–°ã ãŒæ™‚é–“ã‹ã‹ã‚‹ï¼‰\n",
    "        \"\"\"\n",
    "        self.jaspar = JASPARFetcher()\n",
    "        self.fantom5 = FANTOM5Handler()\n",
    "        self.use_jaspar_api = use_jaspar_api\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ğŸ§¬ 1æ¬¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªè¨­è¨ˆã‚·ã‚¹ãƒ†ãƒ  èµ·å‹•\")\n",
    "        print(\"=\"*70)\n",
    "        if use_jaspar_api:\n",
    "            print(\"âš ï¸  JASPAR APIä½¿ç”¨: æœ€æ–°ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæ™‚é–“ã‹ã‹ã‚Šã¾ã™ï¼‰\")\n",
    "        else:\n",
    "            print(\"âš¡ é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰: æ—¢çŸ¥ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    def design_screening_library(self,\n",
    "                                 tissues=['liver', 'tcell', 'ubiquitous'],\n",
    "                                 n_cores=15,\n",
    "                                 n_tfbm_per_tissue=5,\n",
    "                                 tfbm_configs=[1, 2],\n",
    "                                 spacer_same=[10, 20, 30],\n",
    "                                 spacer_opposite=[5, 15, 25],\n",
    "                                 output_prefix='screening_library'):\n",
    "        \"\"\"\n",
    "        1æ¬¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ç”Ÿæˆ\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        tissues : list\n",
    "            å¯¾è±¡çµ„ç¹” ['liver', 'tcell', 'ubiquitous']\n",
    "        n_cores : int\n",
    "            ã‚³ã‚¢ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼æ•°\n",
    "        n_tfbm_per_tissue : int\n",
    "            å„çµ„ç¹”ã‚ãŸã‚Šã®TFBMæ•°\n",
    "        tfbm_configs : list\n",
    "            TFBMå€‹æ•° [1, 2] (3ã¯2æ¬¡ç”¨)\n",
    "        spacer_same : list\n",
    "            åŒã˜å´spaceré•·\n",
    "        spacer_opposite : list\n",
    "            åå¯¾å´spaceré•·\n",
    "        output_prefix : str\n",
    "            å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        dict : {tissue: DataFrame}\n",
    "        \"\"\"\n",
    "        all_libraries = {}\n",
    "        \n",
    "        # 1. ã‚³ã‚¢ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼å–å¾—\n",
    "        print(\"=\"*70)\n",
    "        print(\"ã‚¹ãƒ†ãƒƒãƒ—1: ã‚³ã‚¢ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼å–å¾—\")\n",
    "        print(\"=\"*70)\n",
    "        cores = self.fantom5.get_core_promoters(n=n_cores)\n",
    "        print(f\"ğŸ“Š ä½¿ç”¨ã‚³ã‚¢æ•°: {len(cores)}\\n\")\n",
    "        \n",
    "        # 2. å„çµ„ç¹”ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç”Ÿæˆ\n",
    "        for tissue in tissues:\n",
    "            print(\"\\n\" + \"=\"*70)\n",
    "            print(f\"ã‚¹ãƒ†ãƒƒãƒ—2: {tissue.upper()} ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç”Ÿæˆ\")\n",
    "            print(\"=\"*70)\n",
    "            \n",
    "            # 2-1. TFãƒªã‚¹ãƒˆå–å¾—\n",
    "            tf_list = self.fantom5.get_tissue_tfs(tissue, priority='high', \n",
    "                                                  max_n=n_tfbm_per_tissue)\n",
    "            print(f\"ğŸ¯ å¯¾è±¡TF: {', '.join(tf_list)}\")\n",
    "            \n",
    "            # 2-2. TFBMãƒ¢ãƒãƒ¼ãƒ•å–å¾—ï¼ˆJASPARï¼‰\n",
    "            tfbm_motifs = self.jaspar.fetch_multiple_motifs(tf_list, \n",
    "                                                           use_api=self.use_jaspar_api)\n",
    "            \n",
    "            # ç¸®é‡å¡©åŸºã‚’å±•é–‹\n",
    "            tfbm_sequences = []\n",
    "            for tf, motif in tfbm_motifs.items():\n",
    "                expanded = self._expand_all_degenerate(motif)\n",
    "                tfbm_sequences.extend(expanded[:2])  # å„TFã‹ã‚‰2é…åˆ—ã¾ã§\n",
    "            \n",
    "            print(f\"ğŸ“ TFBMé…åˆ—æ•°: {len(tfbm_sequences)}\")\n",
    "            \n",
    "            # 2-3. å„TFBMå€‹æ•°ã§ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç”Ÿæˆ\n",
    "            tissue_libraries = []\n",
    "            \n",
    "            for n_tfbm in tfbm_configs:\n",
    "                print(f\"\\n  ğŸ”§ TFBM x{n_tfbm} æ§‹æˆã‚’ç”Ÿæˆä¸­...\")\n",
    "                \n",
    "                lib = self._generate_library_core(\n",
    "                    cores=cores,\n",
    "                    tfbm_pool=tfbm_sequences,\n",
    "                    n_tfbm=n_tfbm,\n",
    "                    spacer_same=spacer_same,\n",
    "                    spacer_opposite=spacer_opposite,\n",
    "                    tissue=tissue\n",
    "                )\n",
    "                \n",
    "                tissue_libraries.append(lib)\n",
    "                print(f\"  âœ… {len(lib)}å€‹ã®ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼ç”Ÿæˆ\")\n",
    "            \n",
    "            # 2-4. çµ±åˆ\n",
    "            combined_lib = pd.concat(tissue_libraries, ignore_index=True)\n",
    "            all_libraries[tissue] = combined_lib\n",
    "            \n",
    "            # 2-5. CSVå‡ºåŠ›\n",
    "            output_file = f\"{output_prefix}_{tissue}.csv\"\n",
    "            combined_lib.to_csv(output_file, index=False)\n",
    "            print(f\"\\nğŸ’¾ ä¿å­˜: {output_file}\")\n",
    "            print(f\"ğŸ“Š ç·ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼æ•°: {len(combined_lib):,}\")\n",
    "        \n",
    "        # 3. ã‚µãƒãƒªãƒ¼\n",
    "        self._print_summary(all_libraries)\n",
    "        \n",
    "        return all_libraries\n",
    "    \n",
    "    def _generate_library_core(self, cores, tfbm_pool, n_tfbm, \n",
    "                               spacer_same, spacer_opposite, tissue):\n",
    "        \"\"\"ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å®Ÿéš›ã®çµ„ã¿ç«‹ã¦\"\"\"\n",
    "        library = []\n",
    "        \n",
    "        # Spacerçµ„ã¿åˆã‚ã›\n",
    "        all_spacers = spacer_same + spacer_opposite\n",
    "        spacer_combos = list(product(all_spacers, repeat=n_tfbm))\n",
    "        \n",
    "        # TFBMçµ„ã¿åˆã‚ã›\n",
    "        tfbm_combos = list(product(tfbm_pool, repeat=n_tfbm))\n",
    "        \n",
    "        # ã‚µã‚¤ã‚ºåˆ¶å¾¡: ã‚ã¾ã‚Šã«å¤§ãã„å ´åˆã¯ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
    "        max_tfbm_combos = 50  # 1æ¬¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã«åˆ¶é™\n",
    "        if len(tfbm_combos) > max_tfbm_combos:\n",
    "            tfbm_combos = random.sample(tfbm_combos, max_tfbm_combos)\n",
    "        \n",
    "        # ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼çµ„ã¿ç«‹ã¦\n",
    "        for idx, (core, tfbm_combo, spacer_combo) in enumerate(\n",
    "            product(cores, tfbm_combos, spacer_combos), 1\n",
    "        ):\n",
    "            # Spacerç”Ÿæˆ\n",
    "            spacers = [generate_bdna_friendly_spacer(length) for length in spacer_combo]\n",
    "            \n",
    "            # é…åˆ—çµ„ã¿ç«‹ã¦: [TFBM_n] --sp_n-- ... --[TFBM_1] --sp_1-- [Core]\n",
    "            sequence = core\n",
    "            for tfbm, spacer in zip(tfbm_combo, spacers):\n",
    "                sequence = tfbm + spacer + sequence\n",
    "            \n",
    "            # ãƒˆãƒãƒ­ã‚¸ãƒ¼åˆ†é¡\n",
    "            topology = self._classify_topology(spacer_combo, spacer_same, spacer_opposite)\n",
    "            \n",
    "            # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä½œæˆ\n",
    "            entry = {\n",
    "                'Promoter_ID': f'{tissue.upper()}_P{n_tfbm}_{idx:06d}',\n",
    "                'Tissue': tissue,\n",
    "                'N_TFBM': n_tfbm,\n",
    "                'Core_Promoter': core,\n",
    "                'Full_Sequence': sequence,\n",
    "                'Length': len(sequence),\n",
    "                'Topology': topology,\n",
    "                'GC_Content': self._calc_gc(sequence),\n",
    "            }\n",
    "            \n",
    "            # TFBMè©³ç´°\n",
    "            for i, tfbm in enumerate(tfbm_combo, 1):\n",
    "                entry[f'TFBM_{i}'] = tfbm\n",
    "            \n",
    "            # Spacerè©³ç´°\n",
    "            for i, (spacer, length) in enumerate(zip(spacers, spacer_combo), 1):\n",
    "                entry[f'Spacer_{i}_Length'] = length\n",
    "                entry[f'Spacer_{i}_Seq'] = spacer\n",
    "                entry[f'Spacer_{i}_GC'] = self._calc_gc(spacer)\n",
    "            \n",
    "            library.append(entry)\n",
    "        \n",
    "        return pd.DataFrame(library)\n",
    "    \n",
    "    def _classify_topology(self, spacer_lengths, same_list, opposite_list):\n",
    "        \"\"\"ãƒˆãƒãƒ­ã‚¸ãƒ¼åˆ†é¡\"\"\"\n",
    "        topo = []\n",
    "        for length in spacer_lengths:\n",
    "            if length in same_list:\n",
    "                topo.append('S')\n",
    "            elif length in opposite_list:\n",
    "                topo.append('O')\n",
    "            else:\n",
    "                topo.append('?')\n",
    "        return '-'.join(topo)\n",
    "    \n",
    "    def _calc_gc(self, sequence):\n",
    "        \"\"\"GCå«é‡è¨ˆç®—\"\"\"\n",
    "        if len(sequence) == 0:\n",
    "            return 0\n",
    "        return (sequence.count('G') + sequence.count('C')) / len(sequence) * 100\n",
    "    \n",
    "    def _expand_all_degenerate(self, sequence):\n",
    "        \"\"\"ç¸®é‡å¡©åŸºã‚’å…¨å±•é–‹ï¼ˆè¤‡æ•°é…åˆ—ã‚’è¿”ã™ï¼‰\"\"\"\n",
    "        degenerate_map = {\n",
    "            'W': ['A', 'T'], 'Y': ['C', 'T'], 'R': ['A', 'G'],\n",
    "            'N': ['A', 'T', 'G', 'C'], 'S': ['G', 'C'], 'K': ['G', 'T'],\n",
    "            'M': ['A', 'C'], 'V': ['A', 'C', 'G'], \n",
    "            'H': ['A', 'C', 'T'], 'D': ['A', 'G', 'T'],\n",
    "        }\n",
    "        \n",
    "        def expand_recursive(seq):\n",
    "            for i, base in enumerate(seq):\n",
    "                if base in degenerate_map:\n",
    "                    results = []\n",
    "                    for alt in degenerate_map[base]:\n",
    "                        new_seq = seq[:i] + alt + seq[i+1:]\n",
    "                        results.extend(expand_recursive(new_seq))\n",
    "                    return results\n",
    "            return [seq]\n",
    "        \n",
    "        expanded = expand_recursive(sequence)\n",
    "        # æ•°ãŒå¤šã™ãã‚‹å ´åˆã¯ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
    "        if len(expanded) > 10:\n",
    "            return random.sample(expanded, 10)\n",
    "        return expanded\n",
    "    \n",
    "    def _print_summary(self, all_libraries):\n",
    "        \"\"\"ã‚µãƒãƒªãƒ¼è¡¨ç¤º\"\"\"\n",
    "        print(\"\\n\\n\" + \"=\"*70)\n",
    "        print(\"ğŸ“Š 1æ¬¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ©ã‚¤ãƒ–ãƒ©ãƒª - æœ€çµ‚ã‚µãƒãƒªãƒ¼\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        total = 0\n",
    "        for tissue, lib_df in all_libraries.items():\n",
    "            print(f\"\\nã€{tissue.upper()}ã€‘\")\n",
    "            print(f\"  ç·ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼æ•°: {len(lib_df):,}\")\n",
    "            print(f\"  é…åˆ—é•·ç¯„å›²: {lib_df['Length'].min()}-{lib_df['Length'].max()} bp\")\n",
    "            print(f\"  GCå«é‡ç¯„å›²: {lib_df['GC_Content'].min():.1f}-{lib_df['GC_Content'].max():.1f}%\")\n",
    "            print(f\"  ãƒˆãƒãƒ­ã‚¸ãƒ¼ç¨®é¡: {lib_df['Topology'].nunique()}\")\n",
    "            total += len(lib_df)\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ğŸ¯ å…¨çµ„ç¹”åˆè¨ˆ: {total:,} ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ä½¿ç”¨ä¾‹\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ§¬ 1æ¬¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼ãƒ©ã‚¤ãƒ–ãƒ©ãƒªè¨­è¨ˆ\")\n",
    "    print(\"   å¯¾è±¡: è‚è‡“ + CD3+Tç´°èƒ + ãƒ¦ãƒ“ã‚­ã‚¿ã‚¹\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªè¨­è¨ˆ\n",
    "    # ============================================================\n",
    "    \n",
    "    designer = ScreeningLibraryDesigner(\n",
    "        use_jaspar_api=False  # True=JASPAR APIä½¿ç”¨ï¼ˆé…ã„ï¼‰ã€False=æ—¢çŸ¥ãƒ‡ãƒ¼ã‚¿ï¼ˆé€Ÿã„ï¼‰\n",
    "    )\n",
    "    \n",
    "    # 1æ¬¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç”Ÿæˆ\n",
    "    libraries = designer.design_screening_library(\n",
    "        tissues=['liver', 'tcell', 'ubiquitous'],\n",
    "        n_cores=15,              # ã‚³ã‚¢ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚¿ãƒ¼æ•°ï¼ˆãƒãƒ©ãƒ³ã‚¹å‹ï¼‰\n",
    "        n_tfbm_per_tissue=5,     # å„çµ„ç¹”ã®TFæ•°ï¼ˆå³é¸ï¼‰\n",
    "        tfbm_configs=[1, 2],     # TFBM x1, x2ï¼ˆx3ã¯2æ¬¡ç”¨ï¼‰\n",
    "        spacer_same=[10, 20, 30],      # åŒã˜å´spacerï¼ˆ3ç¨®é¡ï¼‰\n",
    "        spacer_opposite=[5, 15, 25],   # åå¯¾å´spacerï¼ˆ3ç¨®é¡ï¼‰\n",
    "        output_prefix='screening_1st'\n",
    "    )\n",
    "    \n",
    "    # ============================================================\n",
    "    # å„çµ„ç¹”ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ç¢ºèª\n",
    "    # ============================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ“‹ ç”Ÿæˆã•ã‚ŒãŸãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è©³ç´°\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for tissue, lib_df in libraries.items():\n",
    "        print(f\"\\n--- {tissue.upper()} ---\")\n",
    "        print(lib_df[['Promoter_ID', 'N_TFBM', 'Topology', 'Length', 'GC_Content']].head(10))\n",
    "        print(f\"\\nãƒˆãƒãƒ­ã‚¸ãƒ¼åˆ†å¸ƒ:\")\n",
    "        print(lib_df['Topology'].value_counts())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"âœ… 1æ¬¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç”Ÿæˆå®Œäº†ï¼\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:\")\n",
    "    print(\"  - screening_1st_liver.csv\")\n",
    "    print(\"  - screening_1st_tcell.csv\")\n",
    "    print(\"  - screening_1st_ubiquitous.csv\")\n",
    "    print(\"\\nğŸ”¬ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:\")\n",
    "    print(\"  1. ã“ã‚Œã‚‰ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ãƒ«ã‚·ãƒ•ã‚§ãƒ©ãƒ¼ã‚¼ã‚¢ãƒƒã‚»ã‚¤\")\n",
    "    print(\"  2. æ´»æ€§ã®é«˜ã„å€™è£œã‚’ç‰¹å®š\")\n",
    "    print(\"  3. æœ‰æœ›ãªçµ„ã¿åˆã‚ã›ã§2æ¬¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’è¨­è¨ˆ\")\n",
    "    print(\"=\"*70 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
